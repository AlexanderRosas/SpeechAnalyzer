# ğŸ¤ Speech Analyzer AI - Asistente de Oratoria Inteligente

> Un sistema de anÃ¡lisis en tiempo real para entrenamiento de oratoria y debate, utilizando VisiÃ³n por Computadora y Procesamiento de Lenguaje Natural (NLP) offline.

![Estado del Proyecto](https://img.shields.io/badge/Estado-Prototipo%20Funcional-green)
![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![LibrerÃ­as](https://img.shields.io/badge/Libs-OpenCV%20|%20MediaPipe%20|%20Vosk-orange)

## ğŸ“‹ DescripciÃ³n

**Speech Analyzer AI** es una herramienta diseÃ±ada para ayudar a estudiantes, oradores y debatientes a mejorar su comunicaciÃ³n no verbal y la coherencia de su discurso. 

El sistema utiliza **FusiÃ³n de Sensores (Sensor Fusion)** para cruzar datos visuales (gestos faciales y corporales) con datos auditivos (anÃ¡lisis de sentimiento del texto hablado) en tiempo real. El objetivo es detectar la **Congruencia Emocional**: Â¿Coincide lo que dices con la cara que pones?

## ğŸš€ CaracterÃ­sticas Principales

- **ğŸ‘ï¸ AnÃ¡lisis Facial en Tiempo Real:** DetecciÃ³n de sonrisas, ceÃ±o fruncido, apertura de boca y gestos corporales (manos levantadas) usando *MediaPipe*.
- **ğŸ—£ï¸ TranscripciÃ³n Offline:** Uso de la librerÃ­a *Vosk* para transcripciÃ³n de voz a texto sin necesidad de internet y con baja latencia.
- **ğŸ§  DetecciÃ³n de Congruencia:** Algoritmo lÃ³gico que compara el sentimiento del texto (Positivo/Negativo) con la expresiÃ³n facial para alertar incongruencias (ej. decir algo triste sonriendo).
- **ğŸ“Š Dashboard Visual:** Interfaz grÃ¡fica construida con OpenCV que muestra mÃ©tricas, semÃ¡foro de coherencia y transcripciÃ³n en vivo.
- **ğŸ’¾ Registro de Sesiones:** ExportaciÃ³n automÃ¡tica de datos a CSV para anÃ¡lisis posterior.

## ğŸ› ï¸ InstalaciÃ³n y ConfiguraciÃ³n

Sigue estos pasos para ejecutar el proyecto en tu entorno local.

### Prerrequisitos
- Python 3.8 o superior.
- Webcam y MicrÃ³fono funcionales.

### 1. Clonar el repositorio
```bash
git clone [https://github.com/AlexanderRosas/SpeechAnalyzer)
cd SpeechAnalyzer
```

### 2. Crear Entorno Virtual
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Mac/Linux
python3 -m venv venv
source venv/bin/activate
```

### 3. Instalar Dependencias
```bash
pip install -r requirements.txt
```

### 4. Configurar Modelo de Voz
1. Este proyecto usa Vosk (offline). Debes descargar el modelo manualmente:
2. Ve a Vosk Models.
3. Descarga el modelo vosk-model-small-es-0.42 (o la versiÃ³n en espaÃ±ol que prefieras).
4. Descomprime el archivo .zip.
5. Renombra la carpeta extraÃ­da simplemente a model.
6. Mueve la carpeta model a la raÃ­z del proyecto (junto a main.py).

### ğŸ“‚ Estructura del Proyecto
```PlainText
SpeechAnalyzer/
â”‚
â”œâ”€â”€ data/                  # CSVs generados automÃ¡ticamente con los logs de la sesiÃ³n
â”œâ”€â”€ model/                 # Carpeta del modelo Vosk (Descargada manualmente)
â”‚   â”œâ”€â”€ am/
â”‚   â”œâ”€â”€ conf/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ venv/                  # Entorno virtual
â”œâ”€â”€ main.py                # CÃ³digo fuente principal (LÃ³gica y GUI)
â”œâ”€â”€ requirements.txt       # Dependencias del proyecto
â””â”€â”€ README.md              # DocumentaciÃ³n
```

### ğŸ–¥ï¸ Uso
Una vez configurado, ejecuta el script principal:
```PlainText
python main.py
```

### Controles
  El sistema abrirÃ¡ dos ventanas: Dashboard (Video y MÃ©tricas) y TranscripciÃ³n.
  Presiona la tecla q en cualquiera de las ventanas para detener la sesiÃ³n y guardar el CSV.

### InterpretaciÃ³n del Dashboard
  SemÃ¡foro Verde (COHERENTE): Tu expresiÃ³n facial coincide con el sentimiento de tus palabras.
  SemÃ¡foro Rojo (ALERTA - INCONGRUENCIA):
    - Caso A: EstÃ¡s diciendo algo positivo con cara de enojo/preocupaciÃ³n.
    - Caso B: EstÃ¡s diciendo algo negativo/triste mientras sonrÃ­es (nervios o sarcasmo).
    
### Licencia
Este proyecto es de uso acadÃ©mico y libre distribuciÃ³n.
